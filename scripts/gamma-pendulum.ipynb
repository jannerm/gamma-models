{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gamma-pendulum.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7qRsjdqANUd"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Uw8hYsdejS9z"
      },
      "source": [
        "#@title Clone repo and install dependencies\n",
        "%cd /content\n",
        "!git clone https://github.com/jannerm/gamma-models.git\n",
        "%cd gamma-models\n",
        "%pip install -f https://download.pytorch.org/whl/torch_stable.html torch==1.11.0+cu102\n",
        "%pip install git+https://github.com/jannerm/rlkit.git@5d355ba04145c75f59fcd53823784b5e3329f365\n",
        "%pip install sk-video==1.1.10\n",
        "%pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "QQP13dEajKF7"
      },
      "source": [
        "#@title imports\n",
        "\n",
        "import os\n",
        "import copy\n",
        "from IPython import display\n",
        "import torch\n",
        "\n",
        "from gamma.flows import (\n",
        "    make_conditional_flow,\n",
        "    save_model,\n",
        "    load_model,\n",
        ")\n",
        "from gamma.td.distributions import BootstrapTarget\n",
        "from gamma.td.structs import (\n",
        "    ReplayPool,\n",
        "    Policy,\n",
        ")\n",
        "from gamma.td.utils import (\n",
        "    soft_update_from_to,\n",
        "    format_batch,\n",
        ")\n",
        "from gamma.utils import (\n",
        "    mkdir,\n",
        "    set_device,\n",
        ")\n",
        "\n",
        "from gamma.visualization import (\n",
        "    make_prob_fn,\n",
        "    display_video,\n",
        ")\n",
        "from gamma.visualization.pendulum import (\n",
        "    visualize,\n",
        "    visualize_values,\n",
        ")\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHi7n0U4jKF9"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ihSI45tjKF-"
      },
      "source": [
        "class Args:\n",
        "    ## paths\n",
        "    data_path = 'data/pools/pendulum.pkl'\n",
        "    policy_path = 'data/policies/pendulum.pkl'\n",
        "    save_path = 'logs/pendulum'\n",
        "    \n",
        "    load_epoch = None\n",
        "    device = 'cuda:0'\n",
        "    \n",
        "    ## model\n",
        "    hidden_dims = [256, 256, 256]\n",
        "    sigma = 0.1\n",
        "    \n",
        "    ## training\n",
        "    batch_size = 1024\n",
        "    lr = 1e-4\n",
        "    decay = 1e-5\n",
        "    tau = 0.005\n",
        "    discount = 0.99\n",
        "    sample_discount = 0.9\n",
        "    burnin_discount = 0.5\n",
        "    \n",
        "    n_burnin = 2000\n",
        "    n_steps = 50000\n",
        "    \n",
        "    vis_freq = 100\n",
        "    save_freq = 1000\n",
        "    \n",
        "args = Args()\n",
        "\n",
        "mkdir(args.save_path)\n",
        "set_device(args.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBm6gq14ovsg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzgT4447AmBW"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVjGAPKqjKF-"
      },
      "source": [
        "## load offline data and policy\n",
        "dataset = ReplayPool(args.data_path)\n",
        "policy = Policy(args.policy_path)\n",
        "\n",
        "observation_dim = dataset['observations'].shape[1]\n",
        "action_dim = dataset['actions'].shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQaujfp4AiWr"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsGPUoJ2jKF-"
      },
      "source": [
        "## like most single-step models, the gamma-model \n",
        "## is conditioned on a state and action\n",
        "condition_dims = {\n",
        "    's': observation_dim,\n",
        "    'a': action_dim,\n",
        "}\n",
        "\n",
        "## initialize conditional spline flow\n",
        "model = make_conditional_flow(observation_dim, args.hidden_dims, condition_dims)\n",
        "\n",
        "## target model is analogous to a target Q-function\n",
        "target_model = copy.deepcopy(model)\n",
        "\n",
        "## bootstrapped target distribution is mixture of \n",
        "## single-step gaussian (with weight `1 - discount`)\n",
        "## and target model (with weight `discount`)\n",
        "bootstrap = BootstrapTarget(target_model, args.discount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GvaNQLvjKF-"
      },
      "source": [
        "if args.load_epoch is not None:\n",
        "    ## load model from disk and copy to target model\n",
        "    load_model(args.save_path, args.load_epoch, model)\n",
        "    soft_update_from_to(model, target_model, tau=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAcHRbW5jKF_"
      },
      "source": [
        "## visualize the randomly-initialized model\n",
        "prob_fn = make_prob_fn(model, policy)\n",
        "visualize(prob_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptHapaa6AwTf"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTOJBzF-jKF_"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
        "criterion = torch.nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd2ED0gljKF_"
      },
      "source": [
        "images = []\n",
        "for i in range(args.n_steps):\n",
        "    \n",
        "    if i < args.n_burnin:\n",
        "        ## initialize model with a lower discount to speed up training\n",
        "        bootstrap.update_discount(args.burnin_discount)\n",
        "        sample_discount = args.burnin_discount\n",
        "    else:\n",
        "        bootstrap.update_discount(args.discount)\n",
        "        sample_discount = args.sample_discount\n",
        "    \n",
        "    ## batch contains the usual Q-learning entries (s, a, s', r, t)\n",
        "    batch = dataset.sample(args.batch_size)\n",
        "\n",
        "    ## condition dicts contain keys (s, a)\n",
        "    condition_dict, next_condition_dict = format_batch(batch, policy)\n",
        "\n",
        "    ## update single-step distribution as N(s', Ïƒ)\n",
        "    bootstrap.update_p(next_condition_dict['s'], sigma=args.sigma)\n",
        "    \n",
        "    ## sample from bootstrapped target distribution\n",
        "    samples = bootstrap.sample(args.batch_size,\n",
        "              condition_dict, next_condition_dict, discount=sample_discount)\n",
        "    \n",
        "    ## get log-prob of samples under both the target distribution and the model\n",
        "    log_prob_target = bootstrap.log_prob(samples, condition_dict, next_condition_dict)\n",
        "    log_prob_model = model.log_prob(samples, condition_dict)\n",
        "    \n",
        "    ## update model toward target distribution\n",
        "    loss = criterion(log_prob_model, log_prob_target)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    ## target model parameters are an exponentially-moving average of model parameters\n",
        "    soft_update_from_to(model, target_model, args.tau)\n",
        "\n",
        "    if i % args.save_freq == 0:\n",
        "        save_model(args.save_path, i, model)\n",
        "\n",
        "    if i % args.vis_freq == 0 and i > 0:\n",
        "        display.clear_output(wait=True)\n",
        "        \n",
        "        print(f'Iteration {i} | Loss: {loss.item():.6f}\\n')\n",
        "        img = visualize(prob_fn, save_path=os.path.join(args.save_path, str(i)), itr=i)\n",
        "        images.append(img)\n",
        "        display_video(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cmbw2rzjKF_"
      },
      "source": [
        "## predict values with discretized grid over the state space\n",
        "## (increase `n_steps` for finer grid but longer runtime)\n",
        "visualize_values(prob_fn, n_steps=20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
